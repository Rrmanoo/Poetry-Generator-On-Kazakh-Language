{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKeG6IdXTJja"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional, Embedding\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 100\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 30\n",
        "# dataset file path\n",
        "FILE_PATH = \"/content/Full_Dataset.txt\"\n",
        "BASENAME = os.path.basename(FILE_PATH)\n",
        "text = open(FILE_PATH, encoding=\"utf-8\").read()\n",
        "text = open(FILE_PATH, encoding=\"utf-8\").read()\n",
        "text = text.lower()\n",
        "text = text.translate(str.maketrans(\"\", \"\", punctuation))"
      ],
      "metadata": {
        "id": "dfEf5-ICTRrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        " \n",
        "text = re.sub(r'[.,0145«»\"\\'-?:!;–—…﻿tacehopty]', '', text)"
      ],
      "metadata": {
        "id": "psoMX4qyYq6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print some stats\n",
        "n_chars = len(text)\n",
        "vocab = ''.join(sorted(set(text)))\n",
        "print(\"unique_chars:\", vocab)\n",
        "n_unique_chars = len(vocab)\n",
        "print(\"Number of characters:\", n_chars)\n",
        "print(\"Number of unique characters:\", n_unique_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZAQUYb3X6c3",
        "outputId": "d58c8714-ad73-48e3-faf9-e20792a0e43e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_chars: \n",
            " əабвгдежзийклмнопрстуфхцчшщъыьэюяіғқңүұһәө\n",
            "Number of characters: 495346\n",
            "Number of unique characters: 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary that converts characters to integers\n",
        "char2int = {c: i for i, c in enumerate(vocab)}\n",
        "# dictionary that converts integers to characters\n",
        "int2char = {i: c for i, c in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "3gx9jSpxYV5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save these dictionaries for later generation\n",
        "pickle.dump(char2int, open(f\"{BASENAME}-char2int.pickle\", \"wb\"))\n",
        "pickle.dump(int2char, open(f\"{BASENAME}-int2char.pickle\", \"wb\"))"
      ],
      "metadata": {
        "id": "yz6DyNZvYgSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert all text into integers\n",
        "encoded_text = np.array([char2int[c] for c in text])\n",
        "# construct tf.data.Dataset object\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "# print first 5 characters\n",
        "for char in char_dataset.take(8):\n",
        "    print(char.numpy(), int2char[char.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPOfiDXFYh-G",
        "outputId": "c40be2b0-012e-41ba-f2c0-cbacf5907f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 б\n",
            "3 а\n",
            "12 й\n",
            "1  \n",
            "4 б\n",
            "17 о\n",
            "14 л\n",
            "36 ғ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(2*sequence_length + 1, drop_remainder=True)\n",
        "\n",
        "for sequence in sequences.take(2):\n",
        "    print(''.join([int2char[i] for i in sequence.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1kiIIrfYweT",
        "outputId": "01fd3f86-f091-4b9a-e00c-f4e990ed74d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "бай болған дəулеті мол тілеуберді\n",
            "байлықпенен меңгерген тамам елді\n",
            "төрт түлік мал өргенде құрттай қайнап\n",
            "құмырсқадай қыбырлап жапқан жерді\n",
            "торқасқалы қазмойын жылқыларын\n",
            "екіүш мыңдап он шақты қосқа бөл\n",
            "ді\n",
            "түйелері түздерде бота тауып\n",
            "қойы жүрген жерінен қозы терді\n",
            "жас кезінде қыз таңдап кезіп елді\n",
            "өз бойына лайықты іздеп теңді\n",
            "мың жылқыны біржола матап беріп\n",
            "алтынай дейтін сұлуды алып еді\n",
            "тоқсан нарғ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sample(sample):\n",
        "    ds = tf.data.Dataset.from_tensors((sample[:sequence_length], sample[sequence_length]))\n",
        "    for i in range(1, (len(sample)-1) // 2):\n",
        "        input_ = sample[i: i+sequence_length]\n",
        "        target = sample[i+sequence_length]\n",
        "        # extend the dataset with these samples by concatenate() method\n",
        "        other_ds = tf.data.Dataset.from_tensors((input_, target))\n",
        "        ds = ds.concatenate(other_ds)\n",
        "    return ds\n",
        "\n",
        "dataset = sequences.flat_map(split_sample)"
      ],
      "metadata": {
        "id": "bdu_q6k1ZCHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_samples(input_, target):\n",
        "    # onehot encode the inputs and the targets\n",
        "    return tf.one_hot(input_, n_unique_chars), tf.one_hot(target, n_unique_chars)\n",
        "\n",
        "dataset = dataset.map(one_hot_samples)"
      ],
      "metadata": {
        "id": "88XhbMOMZZgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print first 2 samples\n",
        "for element in dataset.take(2):\n",
        "    print(\"Input:\", ''.join([int2char[np.argmax(char_vector)] for char_vector in element[0].numpy()]))\n",
        "    print(\"Target:\", int2char[np.argmax(element[1].numpy())])\n",
        "    print(\"Input shape:\", element[0].shape)\n",
        "    print(\"Target shape:\", element[1].shape)\n",
        "    print(\"=\"*50, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZndzL_lZajP",
        "outputId": "779f5eaa-0e48-4a2a-8264-3a06dd5bc1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: бай болған дəулеті мол тілеуберді\n",
            "байлықпенен меңгерген тамам елді\n",
            "төрт түлік мал өргенде құрттай қа\n",
            "Target: й\n",
            "Input shape: (100, 44)\n",
            "Target shape: (44,)\n",
            "================================================== \n",
            "\n",
            "Input: ай болған дəулеті мол тілеуберді\n",
            "байлықпенен меңгерген тамам елді\n",
            "төрт түлік мал өргенде құрттай қай\n",
            "Target: н\n",
            "Input shape: (100, 44)\n",
            "Target shape: (44,)\n",
            "================================================== \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = dataset.repeat().shuffle(1024).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "zl1pelp4ZjLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    LSTM(256, input_shape=(sequence_length, n_unique_chars), return_sequences=True),\n",
        "    Dropout(0.25),\n",
        "    LSTM(256),\n",
        "    Dense(n_unique_chars, activation=\"softmax\"),\n",
        "])"
      ],
      "metadata": {
        "id": "XsBvcdjdZmvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_weights_path = f\"results/{BASENAME}-{sequence_length}.h5\"\n",
        "model.summary()\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQPFmXKc7-Su",
        "outputId": "7d39549b-6732-4af5-b407-f14c6afb93c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 100, 256)          308224    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100, 256)          0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 44)                11308     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 844,844\n",
            "Trainable params: 844,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make results folder if does not exist yet\n",
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "model.fit(ds, steps_per_epoch=(len(encoded_text) - sequence_length) // BATCH_SIZE, epochs=EPOCHS)\n",
        "model.save(model_weights_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mdk5VHo99C3",
        "outputId": "831c6a06-54e1-47d1-de4a-65690d49465a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "3869/3869 [==============================] - 128s 32ms/step - loss: 2.0444 - accuracy: 0.3513\n",
            "Epoch 2/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 1.7490 - accuracy: 0.4344\n",
            "Epoch 3/30\n",
            "3869/3869 [==============================] - 125s 32ms/step - loss: 1.6247 - accuracy: 0.4736\n",
            "Epoch 4/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 1.5332 - accuracy: 0.5026\n",
            "Epoch 5/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 1.4550 - accuracy: 0.5265\n",
            "Epoch 6/30\n",
            "3869/3869 [==============================] - 125s 32ms/step - loss: 1.3884 - accuracy: 0.5473\n",
            "Epoch 7/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 1.3297 - accuracy: 0.5665\n",
            "Epoch 8/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 1.2761 - accuracy: 0.5841\n",
            "Epoch 9/30\n",
            "3869/3869 [==============================] - 125s 32ms/step - loss: 1.2339 - accuracy: 0.5960\n",
            "Epoch 10/30\n",
            "3869/3869 [==============================] - 125s 32ms/step - loss: 1.1906 - accuracy: 0.6099\n",
            "Epoch 11/30\n",
            "3869/3869 [==============================] - 123s 32ms/step - loss: 1.1542 - accuracy: 0.6209\n",
            "Epoch 12/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 1.1254 - accuracy: 0.6301\n",
            "Epoch 13/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 1.0963 - accuracy: 0.6397\n",
            "Epoch 14/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 1.0726 - accuracy: 0.6461\n",
            "Epoch 15/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 1.0494 - accuracy: 0.6535\n",
            "Epoch 16/30\n",
            "3869/3869 [==============================] - 123s 32ms/step - loss: 1.0322 - accuracy: 0.6584\n",
            "Epoch 17/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 1.0133 - accuracy: 0.6649\n",
            "Epoch 18/30\n",
            "3869/3869 [==============================] - 123s 32ms/step - loss: 0.9955 - accuracy: 0.6691\n",
            "Epoch 19/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 0.9816 - accuracy: 0.6739\n",
            "Epoch 20/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 0.9647 - accuracy: 0.6794\n",
            "Epoch 21/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 0.9676 - accuracy: 0.6784\n",
            "Epoch 22/30\n",
            "3869/3869 [==============================] - 125s 32ms/step - loss: 0.9418 - accuracy: 0.6859\n",
            "Epoch 23/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 0.9296 - accuracy: 0.6899\n",
            "Epoch 24/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 0.9195 - accuracy: 0.6928\n",
            "Epoch 25/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 0.9057 - accuracy: 0.6975\n",
            "Epoch 26/30\n",
            "3869/3869 [==============================] - 123s 32ms/step - loss: 0.8947 - accuracy: 0.7004\n",
            "Epoch 27/30\n",
            "3869/3869 [==============================] - 125s 32ms/step - loss: 0.8840 - accuracy: 0.7030\n",
            "Epoch 28/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 0.8758 - accuracy: 0.7065\n",
            "Epoch 29/30\n",
            "3869/3869 [==============================] - 123s 32ms/step - loss: 0.8727 - accuracy: 0.7072\n",
            "Epoch 30/30\n",
            "3869/3869 [==============================] - 124s 32ms/step - loss: 0.8579 - accuracy: 0.7120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating Text**"
      ],
      "metadata": {
        "id": "U8VsS5z8PkuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Activation\n",
        "import os\n",
        "\n",
        "sequence_length = 100\n",
        "# dataset file path\n",
        "FILE_PATH = \"/content/Full_Dataset.txt\"\n",
        "BASENAME = os.path.basename(FILE_PATH)\n",
        "\n",
        "seed = \"ұл туды деп шашулар шашылған жоқ\\n\"\n",
        "\n",
        "# load vocab dictionaries\n",
        "char2int = pickle.load(open(f\"{BASENAME}-char2int.pickle\", \"rb\"))\n",
        "int2char = pickle.load(open(f\"{BASENAME}-int2char.pickle\", \"rb\"))\n",
        "vocab_size = len(char2int)\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(256, input_shape=(sequence_length, vocab_size), return_sequences=True),\n",
        "    Dropout(0.25),\n",
        "    LSTM(256),\n",
        "    Dense(vocab_size, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.load_weights(f\"results/{BASENAME}-{sequence_length}.h5\")\n",
        "\n",
        "s = seed\n",
        "n_chars = 400\n",
        "generated = \"\"\n",
        "for i in tqdm.tqdm(range(n_chars), \"Generating text\"):\n",
        "    # make the input sequence\n",
        "    X = np.zeros((1, sequence_length, vocab_size))\n",
        "    for t, char in enumerate(seed):\n",
        "      X[0, (sequence_length - len(seed)) + t, char2int[char]] = 1\n",
        "    # predict the next character\n",
        "    predicted = model.predict(X, verbose=0)[0]\n",
        "    # converting the vector to an integer\n",
        "    next_index = np.argmax(predicted)\n",
        "    # converting the integer to a character\n",
        "    next_char = int2char[next_index]\n",
        "    # add the character to results\n",
        "    generated += next_char\n",
        "    # shift seed and the predicted character\n",
        "    seed = seed[1:] + next_char\n",
        "\n",
        "print(\"Seed:\", s)\n",
        "print(\"Generated text:\")\n",
        "print(generated)"
      ],
      "metadata": {
        "id": "IbpqwmCe8BP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "013825cb-0a60-4f66-cb2f-0bb42eb2117f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating text: 100%|██████████| 400/400 [00:22<00:00, 17.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: ұл туды деп шашулар шашылған жоқ\n",
            "\n",
            "Generated text:\n",
            "бұл іске түсірмесін жылым жанып\n",
            "әкесі алыс емес қажын алар\n",
            "сандақтас болар ма екен байлар жауын\n",
            "бар болған соң қайта кеп деп қапырған\n",
            "бұл күнде жақындады жан жамалып\n",
            "әкесінің бір шығып жерді жанған\n",
            "екі жетім байырға көрген жанның\n",
            "көнбесем мынау іздеп ауыр тамақ\n",
            "жасында жан жамылып әкесі  деп\n",
            "жүргені байлор қосқа заман тұрып\n",
            "үмітпен параз бермес жаман кетсе\n",
            "келмедім не боп кетті қыздар едім\n",
            "бір кез\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}