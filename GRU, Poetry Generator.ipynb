{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu_9wl2Qlu6M"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1HWR_WU-mGFX",
        "outputId": "896b1ab0-3fa7-41c7-8612-5987d8b5971e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntext = open(\\'/content/шын гашыкпын.txt\\', \\'rb\\').read().decode(encoding=\\'utf-8\\')\\nimport re\\n \\ntext = text.translate(str.maketrans(\"\", \"\", punctuation))\\n\\ntext = text.lower()\\ntext = re.sub(r\\'[.,0145«»\"\\'-?:!;–—…\\ufefftacehopty]\\', \\'\\', text)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "'''\n",
        "Data Cleaning for the purposes of random selecting, but model should learn all the symbols that are used on human-made poems\n",
        "text = open('/content/шын гашыкпын.txt', 'rb').read().decode(encoding='utf-8')\n",
        "import re\n",
        "\n",
        "text = text.translate(str.maketrans(\"\", \"\", punctuation))\n",
        "\n",
        "text = text.lower()\n",
        "text = re.sub(r'[.,0145«»\"\\'-?:!;–—…﻿tacehopty]', '', text)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('/content/Full_Dataset.txt', 'rb').read().decode(encoding='utf-8')"
      ],
      "metadata": {
        "id": "4ve5Q4ZUrHhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "zhVLlgXdmLZ5",
        "outputId": "75bc7174-01a1-4567-b0ad-b636c18582a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffБай болған дəулеті мол Тілеуберді,\\r\\nБайлықпенен меңгерген тамам елді.\\r\\nТөрт түлік мал өргенде құрттай қайнап,\\r\\nҚұмырсқадай қыбырлап жапқан жерді.\\r\\nТор-қасқалы, қазмойын жылқыларын\\r\\nЕкі-үш мыңдап он шақты қосқа бөлді.\\r\\nТүйелері түздерде бота тауып,\\r\\nҚойы жүрген жерінен қозы терді.\\r\\nЖас кезінде қыз таңдап кезіп елді,\\r\\nӨз бойына лайықты іздеп теңді,\\r\\nМың жылқыны біржола матап беріп,\\r\\nАлтынай дейтін сұлуды алып еді.\\r\\nТоқсан нарға жүк артып безеп, жасап,\\r\\nАлтынайға əкесі құл, күң берді.\\r\\nШұнақ деген жігіт пен Тезек атты\\r\\nБір жас қыз, құл, күңдермен ере келді.\\r\\nШұнақ пенен Тезек те қосты көңіл,\\r\\nҚұлдық, күндік болса да көрген өмір,\\r\\nӨздерінше қызықты дəурен сүріп,\\r\\nТəтті өмір тəрізді болды о бір.\\r\\nШөккен түйе, көгенді қозы арасы, –\\r\\nЖата-тұғын мекені күл мен көмір.\\r\\nСөйтіп Шұнақ Тезекпен осы өмірде\\r\\nТірі жанға сездірмей жүрді үш-төрт жыл.\\r\\nСодан кейін құрсақты болып Тезек,\\r\\nТорсық шеге, ақ сазан тапты бір ұл.\\r\\nҰл туды деп шашулар шашылған жок,\\r\\nҚатын жиып қалжа да асылған жоқ.\\r\\nЖөргегі жоқ, қап-қара құрымға орап\\r\\nАлса да, жанның жаны ашыған жоқ.\\r\\nАлтай деп əлдеқалай атын қойды.\\r\\n«Азанменен» құлағы ашылған жоқ.\\r\\nШұнақтың ақжүрегі қуанғаннан\\r\\nКөпке шейін дүрсілдеп басылған жоқ.\\r\\nКүн-күн санап толқыды туған айдай,\\r\\nҚап-қара көз, қыр мұрын, қасқа маңдай,\\r\\nҚаз мойынды, кең иық, сұлу тұлға\\r\\nТіп-тік боп тауда өскен қарағайдай.\\r\\nКір-қожалақ табанын тас тілсе де,\\r\\nЖүдемеді, үдеді гүл боп жайнай.\\r\\nҚозы бақты, қой бақты, отын жақты,\\r\\nЕрте тұрып үнемі кешке жатты.\\r\\nҚұлдан туған неме деп көзге шұқып,\\r\\nКім корінген бір сабап шырылдатты.\\r\\nИтке төгер іркітін оған беріп,\\r\\nБай да жастан ұстады қысып қатты.\\r\\nСол бейнеттің бəрін де көргенімен,\\r\\nБолып өсті ер Алтай ер сымбатты.\\r\\nБір доғал, жасынан бір бетті болды.\\r\\nКекшіл қасқыр сықылды кекті болды.\\r\\nАузынан шыққын сөзден қайтпай-тұғын,\\r\\nСөз ұстағыш қажырлы, сертті болды.\\r\\nСол бірбеткей бетінен қайтпаймын деп,\\r\\nЖасында талайлардан тепкі көрді,\\r\\nБала күннен əлдінің қылығы өтіп,\\r\\nЖас күнінен өзегі өртті болды.\\r\\nЕкі-үш жылдай отасып Тілеуберді,\\r\\nТүнғышы, Алтынайдан бір қыз көрді,\\r\\nСұлушаш қойып атын, ұлан-асыр\\r\\nТой жасап дүрілдетті бүкіл елді.\\r\\nАй мен күндей нұры бар жалғыз ару,\\r\\nБесіктен-ақ бал болып мəпеленді.\\r\\nЕржеткенде күн түсіп бұғағынан,\\r\\nТаң қылды сұлулығы көргендерді.\\r\\nОн алтыға келгенде қыздың жасы,\\r\\nТөгіліп тізесіне түсті шашы,\\r\\nҚаламмен жалғыз сызық тартқандай боп,\\r\\nҚиылды қап-кара боп қиғаш қасы,\\r\\nҚарақат көз, қыр мұрын, ұзын кірпік,\\r\\nТістері меруеттің тізген тасы.\\r\\nБетінен нұры бөртіп, қаны тамған,\\r\\nТолқыған сұлу айдай кесер басы.\\r\\nМойыны иірілген аққу-сынды,\\r\\nТамағы торғындай боп тартты күнді.\\r\\nҚып-қызыл жұқа ерін, оймақ ауыз,\\r\\nҚиылып құмырсқадай белі үзілді.\\r\\nСүйрік саусақ, жұп-жұмыр жұмсақ білек,\\r\\nОрта бойлы- шалқақтау ер пішінді.\\r\\nКөз қарасы көргенді күндей ертіп,\\r\\nІшпей-жемей мас болып көзін жұмды.\\r\\nЕсіркеп, əлдеқалай құты түсіп,\\r\\nНе керек, бай табиғат берген нұрды!..\\r\\nБасына бəт-құндыздан киді бөрік,\\r\\nТізеден қара шашты жіберді өріп,\\r\\nШеберге шашын ылғи маржандатты.\\r\\nБір рет өргеніне бір ат беріп,\\r\\nБірі күтіп, біреуі нөкер болып,\\r\\nСоңынан сұлу қыздар жүрді еріп.\\r\\nӨз алдына оңаша бір ауыл боп,\\r\\nАлты отауды ақ күмбез тікті бөліп.\\r\\nӨңшең торы қасқалы жорғаларды,\\r\\nТұрмандатты шұп-шұбар күміс көміп,\\r\\nҚай уақытта серуенге шығам десе,\\r\\nБəрі даяр керегі, өзінде ерік.\\r\\nСандалды ел мырзасы болып ғашық,\\r\\nТалай жорға, ішікті төкті шашып,\\r\\nБетпе-бетте бір ауыз сөз қата алмай,\\r\\nСұлудың маңайынан жүрді қашып,\\r\\nБетіне сұлу жанды қаратпады,\\r\\nСөзге шешен, ақ жарқын, мінезі ашық.\\r\\nТолған айдай толықсып гүлдей жайнап,\\r\\nКүннен-күнге сұлулық өрледі асып.\\r\\nСұлушаш бала еді аз жыл бұрын,\\r\\nБалалық өмірдің жəй терген гүлін,\\r\\nНе дегенін істетіп, еркелетіп,\\r\\nТілеуберді «қыз» демей, деді – «ұлым»...\\r\\nНеше түрлі қуыршақ істеп сұлу,\\r\\nОтауда отыратын жиып «жүгін...»\\r\\nСол кезде қозы баққан Алтай бала,\\r\\n(Сауыс боп үсті-басы қарақұрым),\\r\\nСоқтығып ойнаған боп қағып кетіп,\\r\\nКөретін Сұлушаштың тартып сырын.\\r\\nСұлушаш сол мезетте күлімсіреп,\\r\\nАлтайға аударатын көздің қырын.\\r\\nӨйтетіні, Алтайға біткен тұлға\\r\\nБайланбаған мүшелі сұлу құлын.\\r\\nОл кезде екеуі де құлын еді,\\r\\nҚұлындай ойнап у болуы\\r\\nОларға бала кезде білінбеді.\\r\\nҚызарып шыға қалған қос қызғалдақ,\\r\\nСуық желді өмірмен үрілмеді.\\r\\nНеге екенін сезбеді өздері де,\\r\\nҚарасса жүректері дірілдеді.\\r\\nОйнақшып қара көздер жаутаңдасып,\\r\\nҚып-қызыл еріндері күбірледі.\\r\\nЖастық-мастық, балалық бəрін жеңіп,\\r\\nӨмірдің шын пердесі түрілмеді...\\r\\nБасқаны Сұлушаштың сүйері жоқ,\\r\\nАлтайдан басқа көңілі иері жоқ,\\r\\nКездескен қай мырзаға кез салса да,\\r\\nІшінде тап Алтайдай біреуі жоқ.\\r\\nАлтайдың тілі оған бұлбұлға ұқсас,\\r\\nСөйлесе майдай майда, сүйегі жоқ.\\r\\nТəңірісі табынатын жалғыз Алтай,\\r\\nӨзінше одан артық киелі жоқ.\\r\\nАлтайды көрмегелі көптен бері,\\r\\nЖүрекке сағыныштың толды шері,\\r\\nОтарға жылқы айдап кеткен Алтай\\r\\nЖыл болды міне елге келмегелі.\\r\\nАлтайдың қосы жүрді Нұраны өрлеп,\\r\\nЖылқыны салған қысқа, жайлы жер деп,\\r\\nСол бет алған жағынан жазғытұрым\\r\\nҚос көшіп Құланөтпес жаққа келмек.\\r\\nСəуір туып, қар беті қабыршыққа\\r\\nАйналғанша, көшті ол қосын теңдеп,\\r\\nБұл бет алған маңайда, ат '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "text[0:5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkI6bgxzmWRK",
        "outputId": "714b68e4-bee7-4eda-c47b-855c939b4f53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiO8Z2dLmnhI"
      },
      "outputs": [],
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8869XK4Amqyb"
      },
      "outputs": [],
      "source": [
        "# The maximum length sentence you want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJGzDx4EmvvS"
      },
      "outputs": [],
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxFUSq9XmxcN"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9bYtIqqmy8q",
        "outputId": "d0f7bf3f-f3da-4ba9-dcda-0512a838b89c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(10, 100), dtype=tf.int64, name=None), TensorSpec(shape=(10, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-fUsQsdm0oX"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITUO5lh7m2rj"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "        tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESGFCaLhm4Pp"
      },
      "outputs": [],
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkiIcivem5d7",
        "outputId": "7603c1a1-cdf1-4974-c50a-69086d0d66b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 100, 121) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0fisvXqm7ZU",
        "outputId": "a19e33bc-7c30-4556-f3e6-c2b73f255b05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (10, None, 256)           30976     \n",
            "                                                                 \n",
            " gru (GRU)                   (10, None, 1024)          3938304   \n",
            "                                                                 \n",
            " dense (Dense)               (10, None, 121)           124025    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,093,305\n",
            "Trainable params: 4,093,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kidvKVnm8zr"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxz6yWi6m_Pb",
        "outputId": "7661e685-15f1-4d46-8729-e5bde8b3efa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 50,  14,  91,  68,  29, 113,  65,  27,   5, 119, 119,  65,  21,\n",
              "        31,  99,  87,  63, 102,  20,  30,  51,   0,  32,  59,  54,  69,\n",
              "       111,  88,  14,  75,   0,  80,  85, 108,  21,  58,   4,  72,  42,\n",
              "        41,  79,  81,  14,  84,  11, 109,  85,  81,  21, 104,  86,  71,\n",
              "        47,  38,  42,  98,  86,  30,  89,  82,  58,  79,  44, 115,  26,\n",
              "        84,   3,  60,   2, 100,   1,  15, 103,  86, 114,  78,  89,  60,\n",
              "       101,  84,  18,  41,  87,  47,  82,  87,  49,  41,  77,  77,  22,\n",
              "        64,  10,  82,  97,   4,  22,  86,  18, 113])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRpyqniOnAua"
      },
      "outputs": [],
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10DsFCr6nCxa"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG4ANFVHnEDN"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwzJpaTMnFln"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck51RbUCnHf7",
        "outputId": "e7900d57-266e-4435-c574-a36fe8a6ac54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/23\n",
            "531/531 [==============================] - 21s 33ms/step - loss: 2.2148\n",
            "Epoch 2/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 1.8554\n",
            "Epoch 3/23\n",
            "531/531 [==============================] - 15s 28ms/step - loss: 1.7120\n",
            "Epoch 4/23\n",
            "531/531 [==============================] - 16s 27ms/step - loss: 1.6102\n",
            "Epoch 5/23\n",
            "531/531 [==============================] - 15s 27ms/step - loss: 1.5266\n",
            "Epoch 6/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 1.4477\n",
            "Epoch 7/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 1.3668\n",
            "Epoch 8/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 1.2823\n",
            "Epoch 9/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 1.1963\n",
            "Epoch 10/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 1.1111\n",
            "Epoch 11/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 1.0355\n",
            "Epoch 12/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.9673\n",
            "Epoch 13/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.9093\n",
            "Epoch 14/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.8718\n",
            "Epoch 15/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.8313\n",
            "Epoch 16/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.8036\n",
            "Epoch 17/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.7878\n",
            "Epoch 18/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.7764\n",
            "Epoch 19/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.7663\n",
            "Epoch 20/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.7770\n",
            "Epoch 21/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.7727\n",
            "Epoch 22/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.7639\n",
            "Epoch 23/23\n",
            "531/531 [==============================] - 16s 28ms/step - loss: 0.7772\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B0P0B_CInI5T",
        "outputId": "5fe37dda-ead4-4731-c9db-2d21185c2ac9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_23'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTAPTuv2nNOO"
      },
      "outputs": [],
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zavpZkw_nPaD",
        "outputId": "5b03b178-680d-4a8c-b111-db851f2cd89c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 256)            30976     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (1, None, 1024)           3938304   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 121)            124025    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,093,305\n",
            "Trainable params: 4,093,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGzFsMJ4nTxB"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string,t):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Number of characters to generate\n",
        "    num_generate = 300\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low temperature results in more predictable text.\n",
        "    # Higher temperature results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    temperature = t\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        # remove the batch dimension\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JHuqx6OnVA7",
        "outputId": "e6e1b223-6a7f-43d4-d1a2-59e46654a104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Жүреді түні бойы жұлдыз санап,\n",
            "Ғашығын іздеп, көзін көкке қадап,\n",
            "Ермегі сүмбі-сынды Торытөбел\n",
            "Оқтаудай ішін тартып қатқан жарап.\n",
            "Нарыға мінген жерден төрт баласына\r\n",
            "Оларды қара көңіл боп тұрсын не?.. Абылай да, –\r\n",
            "Бұлдыр қақ бірін-бірі серпілгендей.\r\n",
            "Байлаулы бала қайнап, амандасып\r\n",
            "Құлақ түр боп жүрген жері үшін,\r\n",
            "Жүгірген арымақтың деп оңбайлап маңайында?\r\n",
            "Көлеңке үй тоқтатқан оңалауға\r\n",
            "Төсенген түрілдейді күйші кетсе,\r\n",
            "Мық\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u'''Жүреді түні бойы жұлдыз санап,\n",
        "Ғашығын іздеп, көзін көкке қадап,\n",
        "Ермегі сүмбі-сынды Торытөбел\n",
        "Оқтаудай ішін тартып қатқан жарап.\n",
        "''',t=0.000001))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}